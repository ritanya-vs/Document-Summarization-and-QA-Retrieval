{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "735a670b",
      "metadata": {
        "id": "735a670b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    BartTokenizer,\n",
        "    BartForConditionalGeneration,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_v3X5lds7J8",
        "outputId": "4bc0dae2-d6c7-4eb1-d330-46866ded3a0a"
      },
      "id": "b_v3X5lds7J8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "model_name = \"facebook/bart-base\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLWE9yratGRz",
        "outputId": "51b5e260-e88c-41eb-9b99-ef55e798c1dc"
      },
      "id": "YLWE9yratGRz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
      ],
      "metadata": {
        "id": "M4zVn1dKtQjo"
      },
      "id": "M4zVn1dKtQjo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = dataset[\"train\"]\n",
        "val_subset = dataset[\"validation\"]\n",
        "test_subset = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "C2MXoz1ytiUi"
      },
      "id": "C2MXoz1ytiUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = {\n",
        "    \"train\": train_subset,\n",
        "    \"validation\": val_subset,\n",
        "    \"test\": test_subset\n",
        "}\n",
        "\n",
        "print(f\"Datasets loaded. Train: {len(dataset['train'])}, Validation: {len(dataset['validation'])}, Test: {len(dataset['test'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9BCv21Mtx1Q",
        "outputId": "cbada7da-ccb5-407b-979c-7a3551758a10"
      },
      "id": "h9BCv21Mtx1Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded. Train: 5000, Validation: 500, Test: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 1024\n",
        "max_target_length = 142\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[\"article\"]\n",
        "    targets = examples[\"highlights\"]\n",
        "\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=max_input_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "    labels = tokenizer(\n",
        "        targets,\n",
        "        max_length=max_target_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "\n",
        "    labels[\"input_ids\"] = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n",
        "        for label in labels[\"input_ids\"]\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "IFA2T_aGtzVS"
      },
      "id": "IFA2T_aGtzVS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = {}\n",
        "for split in dataset:\n",
        "    print(f\"Preprocessing {split} split...\")\n",
        "    tokenized_datasets[split] = dataset[split].map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=dataset[split].column_names,\n",
        "        desc=f\"Preprocessing {split}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QTxlzRFt9oH",
        "outputId": "629dee18-77b9-488c-c741-deda86f0e109"
      },
      "id": "8QTxlzRFt9oH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing train split...\n",
            "Preprocessing validation split...\n",
            "Preprocessing test split...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results/bart-cnn-finetune\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True if torch.cuda.is_available() else False,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "IxqzJXP8t-db"
      },
      "id": "IxqzJXP8t-db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    padding=\"max_length\",\n",
        "    max_length=max_input_length\n",
        ")"
      ],
      "metadata": {
        "id": "L3GcpIqKuBql"
      },
      "id": "L3GcpIqKuBql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0PkKQrOujtp",
        "outputId": "7a2eaddc-0108-43ff-916a-d9a944d54394"
      },
      "id": "D0PkKQrOujtp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ddf7cc25f2e44558318a4b45a4394dcbd935ebc98263beb783a820b5d8a2cc10\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True) #stemming\n",
        "\n",
        "\n",
        "    rouge_scores = {\n",
        "        'rouge1': [],\n",
        "        'rouge2': [],\n",
        "        'rougeL': []\n",
        "    }\n",
        "\n",
        "    for pred, label in zip(decoded_preds, decoded_labels):\n",
        "        scores = scorer.score(label, pred)\n",
        "        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
        "        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
        "        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
        "\n",
        "\n",
        "    results = {\n",
        "        'rouge1': np.mean(rouge_scores['rouge1']), #ROUGE-1: Measures unigrams (single words) overlap.\n",
        "        'rouge2': np.mean(rouge_scores['rouge2']), #ROUGE-2: Measures bigrams (two consecutive words) overlap.\n",
        "        'rougeL': np.mean(rouge_scores['rougeL']) #ROUGE-L: Measures the longest common subsequence (LCS) between the predicted and reference summaries.\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "xu2cRypfuacI"
      },
      "id": "xu2cRypfuacI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlX5ZIOWur_T",
        "outputId": "9f3a3f73-d54a-4d08-80d9-d2316d855516"
      },
      "id": "qlX5ZIOWur_T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-5b960f886c01>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpf1uRq4vhVN",
        "outputId": "a4999bc8-021b-4d14-ebdf-ac64553bc657"
      },
      "id": "gpf1uRq4vhVN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "NhN3QxQWutIg",
        "outputId": "d72904a2-fa81-43ea-ad3c-4468fafd1d3f"
      },
      "id": "NhN3QxQWutIg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10000/10000 1:32:17, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.235600</td>\n",
              "      <td>2.160958</td>\n",
              "      <td>0.240760</td>\n",
              "      <td>0.096323</td>\n",
              "      <td>0.196457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.890700</td>\n",
              "      <td>2.203619</td>\n",
              "      <td>0.241517</td>\n",
              "      <td>0.098583</td>\n",
              "      <td>0.197821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.642400</td>\n",
              "      <td>2.246793</td>\n",
              "      <td>0.247188</td>\n",
              "      <td>0.100915</td>\n",
              "      <td>0.202216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.459800</td>\n",
              "      <td>2.298652</td>\n",
              "      <td>0.247184</td>\n",
              "      <td>0.098647</td>\n",
              "      <td>0.200535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.309700</td>\n",
              "      <td>2.350287</td>\n",
              "      <td>0.246332</td>\n",
              "      <td>0.097544</td>\n",
              "      <td>0.198746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.179400</td>\n",
              "      <td>2.391032</td>\n",
              "      <td>0.247364</td>\n",
              "      <td>0.097333</td>\n",
              "      <td>0.198788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.095700</td>\n",
              "      <td>2.424881</td>\n",
              "      <td>0.245578</td>\n",
              "      <td>0.099136</td>\n",
              "      <td>0.199284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.041700</td>\n",
              "      <td>2.460022</td>\n",
              "      <td>0.247495</td>\n",
              "      <td>0.100014</td>\n",
              "      <td>0.201246</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10000, training_loss=1.4908389038085939, metrics={'train_runtime': 5538.7312, 'train_samples_per_second': 7.222, 'train_steps_per_second': 1.805, 'total_flos': 2.43894583296e+16, 'train_loss': 1.4908389038085939, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./bart-cnn-finetuned\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WayEnkjsuw6y",
        "outputId": "8e32138d-6a9e-4785-ace5-f99c3ab50af9"
      },
      "id": "WayEnkjsuw6y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./bart-cnn-finetuned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(article_text):\n",
        "    inputs = tokenizer(article_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.to(\"cuda\")\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        num_beams=4,\n",
        "        min_length=30,\n",
        "        max_length=max_target_length,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "NrnO5uNfvHHO"
      },
      "id": "NrnO5uNfvHHO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(dataset[\"test\"]) > 0:\n",
        "    sample_idx = 0\n",
        "    sample_article = dataset[\"test\"][sample_idx][\"article\"]\n",
        "    original_summary = dataset[\"test\"][sample_idx][\"highlights\"]\n",
        "\n",
        "    print(\"Sample article:\", sample_article[:500] + \"...\")\n",
        "    print(\"\\nOriginal summary:\", original_summary)\n",
        "\n",
        "    generated_summary = generate_summary(sample_article)\n",
        "    print(\"\\nGenerated summary:\", generated_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NokOhTA2vLex",
        "outputId": "0c7b95ac-381c-458e-c486-ff2ce416081f"
      },
      "id": "NokOhTA2vLex",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample article: (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, includin...\n",
            "\n",
            "Original summary: Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "\n",
            "Generated summary: Palestinians officially become 123rd member of the International Criminal Court .\n",
            "The Rome Statute gives the court jurisdiction over alleged crimes in Palestinian territories .\n",
            "Israel and the United States opposed Palestinians' efforts to join the court .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training and saving the model...\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
        "\n",
        "# Print test ROUGE scores\n",
        "print(\"\\nTest ROUGE Scores:\")\n",
        "print(f\"ROUGE-1: {test_results.metrics['test_rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2: {test_results.metrics['test_rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L: {test_results.metrics['test_rougeL']:.4f}\")\n",
        "\n",
        "# If you want to see individual predictions and their ROUGE scores:\n",
        "print(\"\\nGenerating sample predictions with ROUGE scores...\")\n",
        "\n",
        "# Get the first few examples from the test set\n",
        "num_samples = 3\n",
        "sample_articles = dataset[\"test\"].select(range(num_samples))[\"article\"]\n",
        "sample_highlights = dataset[\"test\"].select(range(num_samples))[\"highlights\"]\n",
        "\n",
        "for i in range(num_samples):\n",
        "    print(f\"\\nSample {i+1}:\")\n",
        "    print(\"Article:\", sample_articles[i][:200] + \"...\")\n",
        "    print(\"Original Summary:\", sample_highlights[i])\n",
        "\n",
        "    # Generate summary\n",
        "    generated_summary = generate_summary(sample_articles[i])\n",
        "    print(\"Generated Summary:\", generated_summary)\n",
        "\n",
        "    # Calculate ROUGE for this single example\n",
        "    from rouge_score import rouge_scorer\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(sample_highlights[i], generated_summary)\n",
        "\n",
        "    print(\"ROUGE Scores for this sample:\")\n",
        "    print(f\"ROUGE-1: {scores['rouge1'].fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "FfJe4JeTTLVn",
        "outputId": "564fe7aa-d73f-447e-818e-9473a0170a23"
      },
      "id": "FfJe4JeTTLVn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test ROUGE Scores:\n",
            "ROUGE-1: 0.2521\n",
            "ROUGE-2: 0.0982\n",
            "ROUGE-L: 0.2030\n",
            "\n",
            "Generating sample predictions with ROUGE scores...\n",
            "\n",
            "Sample 1:\n",
            "Article: (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territor...\n",
            "Original Summary: Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "Generated Summary: Palestinians officially become 123rd member of the International Criminal Court .\n",
            "The Rome Statute gives the court jurisdiction over alleged crimes in Palestinian territories .\n",
            "Israel and the United States opposed Palestinians' efforts to join the court .\n",
            "ROUGE Scores for this sample:\n",
            "ROUGE-1: 0.5217\n",
            "ROUGE-2: 0.3284\n",
            "ROUGE-L: 0.4638\n",
            "\n",
            "Sample 2:\n",
            "Article: (CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided me...\n",
            "Original Summary: Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
            "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
            "Generated Summary: Dog was hit by a car, buried in a field, only to survive .\n",
            "Theia, a friendly white-and-black bully breed mix now named Theia, has been receiving care at the Veterinary Teaching Hospital .\n",
            "Donors have already surpassed the $10,000 target for Theia's treatment .\n",
            "ROUGE Scores for this sample:\n",
            "ROUGE-1: 0.4270\n",
            "ROUGE-2: 0.2299\n",
            "ROUGE-L: 0.2921\n",
            "\n",
            "Sample 3:\n",
            "Article: (CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian foreign minister. He has been U.S. Secretary of Sta...\n",
            "Original Summary: Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
            "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
            "The Iranian foreign minister tweets in English .\n",
            "Generated Summary: Iranian Foreign Minister Mohammad Javad Zarif is U.S. Secretary of State John Kerry's opposite number .\n",
            "Zarif has worked to bring Iran out of the cold and allow it to rejoin international community .\n",
            "He has spent more time with Kerry than any other foreign minister in world .\n",
            "ROUGE Scores for this sample:\n",
            "ROUGE-1: 0.5301\n",
            "ROUGE-2: 0.3951\n",
            "ROUGE-L: 0.3614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vz6MDc9UO4A",
        "outputId": "fdc295cd-70c7-4ba4-8761-9aa9777d7050"
      },
      "id": "4vz6MDc9UO4A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: results/ (stored 0%)\n",
            "  adding: results/bart-cnn-finetune/ (stored 0%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/ (stored 0%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/scaler.pt (deflated 60%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/trainer_state.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/config.json (deflated 64%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/generation_config.json (deflated 45%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/merges.txt (deflated 53%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/vocab.json (deflated 68%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/scheduler.pt (deflated 56%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/special_tokens_map.json (deflated 85%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/tokenizer_config.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/optimizer.pt (deflated 8%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/rng_state.pth (deflated 25%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/training_args.bin (deflated 51%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9000/model.safetensors (deflated 7%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/ (stored 0%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/scaler.pt (deflated 60%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/trainer_state.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/config.json (deflated 64%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/generation_config.json (deflated 45%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/merges.txt (deflated 53%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/vocab.json (deflated 68%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/scheduler.pt (deflated 56%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/special_tokens_map.json (deflated 85%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/tokenizer_config.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/optimizer.pt (deflated 8%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/rng_state.pth (deflated 25%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/training_args.bin (deflated 51%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-10000/model.safetensors (deflated 7%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/ (stored 0%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/scaler.pt (deflated 60%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/trainer_state.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/config.json (deflated 64%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/generation_config.json (deflated 45%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/merges.txt (deflated 53%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/vocab.json (deflated 68%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/scheduler.pt (deflated 55%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/special_tokens_map.json (deflated 85%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/tokenizer_config.json (deflated 75%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/optimizer.pt (deflated 8%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/rng_state.pth (deflated 25%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/training_args.bin (deflated 51%)\n",
            "  adding: results/bart-cnn-finetune/checkpoint-9500/model.safetensors (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('results.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7MqnSBQSUchL",
        "outputId": "16f652a1-fdaf-4665-b181-645fe2d69581"
      },
      "id": "7MqnSBQSUchL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8843a837-3f52-4046-ac4d-f51a5f33f01e\", \"results.zip\", 4615266053)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}