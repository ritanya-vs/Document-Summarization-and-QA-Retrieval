{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zyYAtKAzUE8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from rouge import Rouge\n",
        "import logging\n",
        "import random\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "1U3EOtlf0u6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7s1ZhER7MOc",
        "outputId": "5f29d79d-6522-4ba1-e141-dbc3e577b64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt', quiet=True)\n",
        "nltk_data_path = os.path.join(os.getcwd(), 'nltk_data')\n",
        "nltk.data.path.append(nltk_data_path)\n",
        "print(\"Loading CNN/DailyMail dataset...\")\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXZHvMUf7MZL",
        "outputId": "05b2fe00-e988-42c4-a759-1b4949d0e302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CNN/DailyMail dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_subset = dataset[\"train\"]\n",
        "val_subset = dataset[\"validation\"]\n",
        "test_subset = dataset[\"test\"]\n",
        "\n",
        "\n",
        "dataset = {\n",
        "    \"train\": train_subset,\n",
        "    \"validation\": val_subset,\n",
        "    \"test\": test_subset\n",
        "}\n",
        "\n",
        "print(f\"Train set: {len(dataset['train'])} examples\")\n",
        "print(f\"Validation set: {len(dataset['validation'])} examples\")\n",
        "print(f\"Test set: {len(dataset['test'])} examples\")\n",
        "\n",
        "df_train = pd.DataFrame(dataset['train'])\n",
        "df_val = pd.DataFrame(dataset['validation'])\n",
        "df_test = pd.DataFrame(dataset['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ8-IKZy9x3t",
        "outputId": "fd8f7927-8e48-4a63-e857-bb0dea99b0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 1000 examples\n",
            "Validation set: 100 examples\n",
            "Test set: 100 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSumExtractor(nn.Module):\n",
        "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_labels=2):\n",
        "        super(BertSumExtractor, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "\n",
        "        self.doc_encoder = nn.TransformerEncoderLayer(\n",
        "            d_model=self.bert.config.hidden_size,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048\n",
        "        )\n",
        "        self.doc_transformer = nn.TransformerEncoder(self.doc_encoder, num_layers=2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
        "\n",
        "        batch_size, num_sentences, seq_len = input_ids.size()\n",
        "        input_ids = input_ids.view(-1, seq_len)\n",
        "        attention_mask = attention_mask.view(-1, seq_len)\n",
        "\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids.view(-1, seq_len) if token_type_ids is not None else None\n",
        "        )\n",
        "\n",
        "\n",
        "        sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        sentence_embeddings = sentence_embeddings.view(batch_size, num_sentences, -1)\n",
        "\n",
        "\n",
        "        doc_embeddings = self.doc_transformer(sentence_embeddings)\n",
        "\n",
        "        logits = self.classifier(self.dropout(doc_embeddings))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "\n",
        "            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n",
        "\n",
        "        return logits, loss"
      ],
      "metadata": {
        "id": "e5--_gmB986S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_extractive_data(df):\n",
        "\n",
        "    data = []\n",
        "    skipped = 0\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating extractive data\"):\n",
        "        article = row['article']\n",
        "        highlights = row['highlights']\n",
        "\n",
        "        article_sents = sent_tokenize(article)\n",
        "        highlight_sents = sent_tokenize(highlights)\n",
        "\n",
        "        if len(article_sents) == 0 or len(highlight_sents) == 0:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "\n",
        "        labels = []\n",
        "\n",
        "\n",
        "        for sent in article_sents:\n",
        "\n",
        "            clean_sent = re.sub(r'\\s+', ' ', sent.lower().strip())\n",
        "\n",
        "\n",
        "            best_match_score = 0\n",
        "            best_match_idx = -1\n",
        "\n",
        "            for h_idx, h_sent in enumerate(highlight_sents):\n",
        "                clean_h_sent = re.sub(r'\\s+', ' ', h_sent.lower().strip())\n",
        "\n",
        "\n",
        "                sent_tokens = set(clean_sent.split())\n",
        "                h_tokens = set(clean_h_sent.split())\n",
        "\n",
        "                if len(sent_tokens) == 0 or len(h_tokens) == 0:\n",
        "                    continue\n",
        "\n",
        "                overlap = len(sent_tokens.intersection(h_tokens))\n",
        "                overlap_ratio = overlap / max(len(sent_tokens), len(h_tokens))\n",
        "\n",
        "                if overlap_ratio > best_match_score:\n",
        "                    best_match_score = overlap_ratio\n",
        "                    best_match_idx = h_idx\n",
        "\n",
        "\n",
        "            if best_match_score > 0.5:\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(0)\n",
        "\n",
        "\n",
        "        if sum(labels) == 0 and len(labels) > 0:\n",
        "\n",
        "            sent_scores = []\n",
        "            for sent_idx, sent in enumerate(article_sents):\n",
        "                clean_sent = re.sub(r'\\s+', ' ', sent.lower().strip())\n",
        "                max_score = 0\n",
        "\n",
        "                for h_sent in highlight_sents:\n",
        "                    clean_h_sent = re.sub(r'\\s+', ' ', h_sent.lower().strip())\n",
        "\n",
        "                    sent_tokens = set(clean_sent.split())\n",
        "                    h_tokens = set(clean_h_sent.split())\n",
        "\n",
        "                    if len(sent_tokens) == 0 or len(h_tokens) == 0:\n",
        "                        continue\n",
        "\n",
        "                    overlap = len(sent_tokens.intersection(h_tokens))\n",
        "                    overlap_ratio = overlap / max(len(sent_tokens), len(h_tokens))\n",
        "                    max_score = max(max_score, overlap_ratio)\n",
        "\n",
        "                sent_scores.append((sent_idx, max_score))\n",
        "\n",
        "\n",
        "            sent_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "            for idx, _ in sent_scores[:min(3, len(sent_scores))]:\n",
        "                labels[idx] = 1\n",
        "\n",
        "\n",
        "        data.append({\n",
        "            'article_sents': article_sents,\n",
        "            'labels': labels\n",
        "        })\n",
        "\n",
        "    print(f\"Skipped {skipped} articles due to missing sentences\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "X6d6bfYA-BEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLaYxLgw-aKK",
        "outputId": "b755c9df-e4a4-49d0-f457-51762714ab1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Processing the dataset for extractive summarization...\")\n",
        "extractive_train_data = create_extractive_data(df_train)\n",
        "extractive_val_data = create_extractive_data(df_val)\n",
        "print(f\"Created {len(extractive_train_data)} training examples\")\n",
        "print(f\"Created {len(extractive_val_data)} validation examples\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMSnO1Hh-JP3",
        "outputId": "7aa261a9-bcd0-4131-ad6e-62808cc57c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing the dataset for extractive summarization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating extractive data: 100%|██████████| 1000/1000 [00:03<00:00, 276.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 0 articles due to missing sentences\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating extractive data: 100%|██████████| 100/100 [00:00<00:00, 426.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 0 articles due to missing sentences\n",
            "Created 1000 training examples\n",
            "Created 100 validation examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "R6dgi1tE-VgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtractiveDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=256):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        sentences = item['article_sents']\n",
        "        labels = item['labels']\n",
        "        sentences = sentences[:20]\n",
        "        labels = labels[:20]\n",
        "\n",
        "\n",
        "\n",
        "        encodings = self.tokenizer(\n",
        "            sentences,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encodings['input_ids'],\n",
        "            'attention_mask': encodings['attention_mask'],\n",
        "            'labels': torch.tensor(labels, dtype=torch.long)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "fINr3Fy3-sj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ExtractiveDataset(extractive_train_data, tokenizer,max_length=256)\n",
        "val_dataset = ExtractiveDataset(extractive_val_data, tokenizer,max_length=256)"
      ],
      "metadata": {
        "id": "CKrGr_Gv-1k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    labels = []\n",
        "\n",
        "    for item in batch:\n",
        "        input_ids.append(item['input_ids'])\n",
        "        attention_masks.append(item['attention_mask'])\n",
        "        labels.append(item['labels'])\n",
        "\n",
        "    max_length = max(len(ids) for ids in input_ids)\n",
        "\n",
        "    padded_input_ids = []\n",
        "    padded_attention_masks = []\n",
        "    padded_labels = []\n",
        "\n",
        "    for ids, mask, label in zip(input_ids, attention_masks, labels):\n",
        "\n",
        "        padding_length = max_length - len(ids)\n",
        "        if padding_length > 0:\n",
        "            zero_padding = torch.zeros((padding_length, ids.size(1)), dtype=ids.dtype)\n",
        "            padded_ids = torch.cat([ids, zero_padding], dim=0)\n",
        "\n",
        "            mask_padding = torch.zeros((padding_length, mask.size(1)), dtype=mask.dtype)\n",
        "            padded_mask = torch.cat([mask, mask_padding], dim=0)\n",
        "\n",
        "\n",
        "            label_padding = torch.ones(padding_length, dtype=torch.long) * -100\n",
        "            padded_label = torch.cat([label, label_padding], dim=0)\n",
        "        else:\n",
        "            padded_ids = ids\n",
        "            padded_mask = mask\n",
        "            padded_label = label\n",
        "\n",
        "        padded_input_ids.append(padded_ids)\n",
        "        padded_attention_masks.append(padded_mask)\n",
        "        padded_labels.append(padded_label)\n",
        "\n",
        "    return {\n",
        "        'input_ids': torch.stack(padded_input_ids),\n",
        "        'attention_mask': torch.stack(padded_attention_masks),\n",
        "        'labels': torch.stack(padded_labels)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Og_QArOu-34A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2  # Adjust based on your GPU memory\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "bJrU-Utt-_fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing the BertSum model...\")\n",
        "model = BertSumExtractor().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxqbJ_Sx_IZi",
        "outputId": "6cb1b72c-2b48-4cbc-8f74-56835ecc8805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the BertSum model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_epochs = 3\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "dv4sbZBp_Nb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def train():\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n======== Epoch {epoch+1} / {num_epochs} ========\")\n",
        "\n",
        "\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for step, batch in enumerat# Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            logits, loss = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            if step % 100 == 0 and step != 0:\n",
        "                logger.info(f\"Epoch: {epoch+1}/{num_epochs} | Step: {step}/{len(train_dataloader)} | Loss: {loss.item()}\")\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "        print(f\"Average training loss: {avg_train_loss}\")\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                logits, loss = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "                valid_indices = labels != -100\n",
        "\n",
        "                all_preds.extend(preds[valid_indices].cpu().numpy())\n",
        "                all_labels.extend(labels[valid_indices].cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "        accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "        print(f\"Validation loss: {avg_val_loss}\")\n",
        "        print(f\"Validation accuracy: {accuracy}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            print(\"Saving best model...\")\n",
        "            torch.save(model.state_dict(), \"best_bertsum_model.pt\")\n",
        "\n",
        "    print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "N6BamN9b_XcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhusoNt5_e66",
        "outputId": "37174d1b-ed46-4b61-800a-d2dc2fe75f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "\n",
            "======== Epoch 1 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 500/500 [16:28<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.3687620839253068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.37115209728479387\n",
            "Validation accuracy: 0.8764501160092807\n",
            "Saving best model...\n",
            "\n",
            "======== Epoch 2 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 500/500 [16:30<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.30995405465364456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 50/50 [00:25<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3929674586653709\n",
            "Validation accuracy: 0.8723897911832946\n",
            "\n",
            "======== Epoch 3 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 500/500 [16:29<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.24253470274806022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 50/50 [00:25<00:00,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4343030548095703\n",
            "Validation accuracy: 0.8683294663573086\n",
            "Training completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading best model for inference...\")\n",
        "model.load_state_dict(torch.load(\"best_bertsum_model.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7wBLHhxRSn1",
        "outputId": "574921fd-5722-4816-dc1a-a0a46f3aded5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model for inference...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSumExtractor(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (doc_encoder): TransformerEncoderLayer(\n",
              "    (self_attn): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "    )\n",
              "    (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout1): Dropout(p=0.1, inplace=False)\n",
              "    (dropout2): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (doc_transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_article(article, model, tokenizer, top_n=3):\n",
        "\n",
        "    sentences = sent_tokenize(article)\n",
        "    if len(sentences) == 0:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in sentences:\n",
        "        encoded = tokenizer(\n",
        "            sent,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0).unsqueeze(0)\n",
        "    attention_mask = torch.cat(attention_masks, dim=0).unsqueeze(0)\n",
        "\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "\n",
        "    sentence_scores = torch.softmax(logits, dim=-1)[0, :, 1].cpu().numpy()\n",
        "\n",
        "    top_n = min(top_n, len(sentences))\n",
        "    top_indices = np.argsort(sentence_scores)[-top_n:]\n",
        "    top_indices = sorted(top_indices)\n",
        "\n",
        "\n",
        "    summary = ' '.join([sentences[i] for i in top_indices])\n",
        "    return summary\n",
        "\n",
        "\n",
        "def evaluate_model(model, tokenizer, test_df, sample_size=100):\n",
        "    \"\"\"Evaluate model on test set and calculate ROUGE scores\"\"\"\n",
        "    print(\"Evaluating the model on test set...\")\n",
        "    summaries = []\n",
        "    rouge_scores = []\n",
        "    rouge_calculator = Rouge()\n",
        "\n",
        "    test_sample = test_df.sample(min(sample_size, len(test_df)))\n",
        "\n",
        "    for idx, row in tqdm(test_sample.iterrows(), total=len(test_sample), desc=\"Generating summaries\"):\n",
        "        article = row['article']\n",
        "        original_summary = row['highlights']\n",
        "\n",
        "        try:\n",
        "\n",
        "            generated_summary = summarize_article(article, model, tokenizer)\n",
        "            summaries.append(generated_summary)\n",
        "\n",
        "\n",
        "            score = rouge_calculator.get_scores(generated_summary, original_summary)[0]\n",
        "            rouge_scores.append(score)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing article {idx}: {str(e)}\")\n",
        "            summaries.append(\"\")\n",
        "            rouge_scores.append({'rouge-1': {'f': 0}, 'rouge-2': {'f': 0}, 'rouge-l': {'f': 0}})\n",
        "\n",
        "\n",
        "    rouge_1_f = np.mean([score['rouge-1']['f'] for score in rouge_scores])\n",
        "    rouge_2_f = np.mean([score['rouge-2']['f'] for score in rouge_scores])\n",
        "    rouge_l_f = np.mean([score['rouge-l']['f'] for score in rouge_scores])\n",
        "\n",
        "    print(f\"\\nAverage ROUGE-1 F1: {rouge_1_f:.4f}\")\n",
        "    print(f\"Average ROUGE-2 F1: {rouge_2_f:.4f}\")\n",
        "    print(f\"Average ROUGE-L F1: {rouge_l_f:.4f}\")\n",
        "\n",
        "\n",
        "    test_sample['generated_summary'] = summaries\n",
        "    test_sample[['article', 'highlights', 'generated_summary']].to_csv('bertsum_results.csv', index=False)\n",
        "    print(\"Results saved to 'bertsum_results.csv'\")\n",
        "\n",
        "    return test_sample\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pg7xe23jRU4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = evaluate_model(model, tokenizer, df_test, sample_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slrQQ4GvRdCP",
        "outputId": "3de52f3d-8bef-4b6f-cf59-d3f3966dc95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating summaries: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average ROUGE-1 F1: 0.2673\n",
            "Average ROUGE-2 F1: 0.0959\n",
            "Average ROUGE-L F1: 0.2465\n",
            "Results saved to 'bertsum_results.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summaries = []\n",
        "rouge_scores = []\n",
        "rouge_calculator = Rouge()\n",
        "\n",
        "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Generating summaries\"):\n",
        "    article = row['article']\n",
        "    original_summary = row['highlights']\n",
        "\n",
        "    try:\n",
        "\n",
        "        generated_summary = summarize_article(article, model, tokenizer)\n",
        "        summaries.append(generated_summary)\n",
        "\n",
        "\n",
        "        score = rouge_calculator.get_scores(generated_summary, original_summary)[0]\n",
        "        rouge_scores.append(score)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing article {idx}: {str(e)}\")\n",
        "        summaries.append(\"[SUMMARY GENERATION FAILED]\")  # Placeholder for failed cases\n",
        "        rouge_scores.append({'rouge-1': {'f': 0}, 'rouge-2': {'f': 0}, 'rouge-l': {'f': 0}})\n",
        "\n",
        "if len(summaries) == len(df_test):\n",
        "    df_test['bertsum_summary'] = summaries\n",
        "    df_test[['article', 'highlights', 'bertsum_summary']].to_csv('bertsum_results.csv', index=False)\n",
        "    print(\"Results saved to 'bertsum_results.csv'\")\n",
        "\n",
        "\n",
        "    print(\"\\n===== Sample Summaries =====\")\n",
        "    for i in range(min(5, len(df_test))):\n",
        "        print(f\"\\nOriginal Article (first 100 chars): {df_test.iloc[i]['article'][:100]}...\")\n",
        "        print(f\"\\nOriginal Summary: {df_test.iloc[i]['highlights']}\")\n",
        "        print(f\"\\nGenerated Summary: {df_test.iloc[i]['bertsum_summary']}\")\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "else:\n",
        "    print(f\"Error: Generated {len(summaries)} summaries but have {len(df_test)} test articles\")\n",
        "\n",
        "\n",
        "if len(rouge_scores) > 0:\n",
        "    rouge_1_f = np.mean([score['rouge-1']['f'] for score in rouge_scores])\n",
        "    rouge_2_f = np.mean([score['rouge-2']['f'] for score in rouge_scores])\n",
        "    rouge_l_f = np.mean([score['rouge-l']['f'] for score in rouge_scores])\n",
        "\n",
        "    print(f\"\\nAverage ROUGE-1 F1: {rouge_1_f:.4f}\")\n",
        "    print(f\"Average ROUGE-2 F1: {rouge_2_f:.4f}\")\n",
        "    print(f\"Average ROUGE-L F1: {rouge_l_f:.4f}\")\n",
        "\n",
        "print(\"\\nComplete! Evaluation finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwrjA808RmJ1",
        "outputId": "e396a475-506f-48b2-e58f-800d4d066a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating summaries: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'bertsum_results.csv'\n",
            "\n",
            "===== Sample Summaries =====\n",
            "\n",
            "Original Article (first 100 chars): (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Cour...\n",
            "\n",
            "Original Summary: Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "\n",
            "Generated Summary: (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article (first 100 chars): (CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three...\n",
            "\n",
            "Original Summary: Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
            "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
            "\n",
            "Generated Summary: She was taken in by Moses Lake, Washington, resident Sara Mellado. Theia is not the only animal to apparently rise from the grave in recent weeks. A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor's yard five days after he was buried by his owner.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article (first 100 chars): (CNN)If you've been following the news lately, there are certain things you doubtless know about Moh...\n",
            "\n",
            "Original Summary: Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister .\n",
            "He once participated in a takeover of the Iranian Consulate in San Francisco .\n",
            "The Iranian foreign minister tweets in English .\n",
            "\n",
            "Generated Summary: In September 2013, Zarif tweeted \"Happy Rosh Hashanah,\" referring to the Jewish New Year. Zarif was nominated to be foreign minister by Ahmadinejad's successor, Hassan Rouhami. Early in the Iranian Revolution, Zarif was among the students who took over the Iranian Consulate in San Francisco.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article (first 100 chars): (CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being e...\n",
            "\n",
            "Original Summary: 17 Americans were exposed to the Ebola virus while in Sierra Leone in March .\n",
            "Another person was diagnosed with the disease and taken to hospital in Maryland .\n",
            "National Institutes of Health says the patient is in fair condition after weeks of treatment .\n",
            "\n",
            "Generated Summary: (CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released, a Nebraska Medicine spokesman said in an email Wednesday. They were exposed to Ebola in Sierra Leone in March, but none developed the deadly virus. More than 10,000 people have died in a West African epidemic of Ebola that dates to December 2013, according to the World Health Organization.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article (first 100 chars): (CNN)A Duke student has admitted to hanging a noose made of rope from a tree near a student union, u...\n",
            "\n",
            "Original Summary: Student is no longer on Duke University campus and will face disciplinary review .\n",
            "School officials identified student during investigation and the person admitted to hanging the noose, Duke says .\n",
            "The noose, made of rope, was discovered on campus about 2 a.m.\n",
            "\n",
            "Generated Summary: (CNN)A Duke student has admitted to hanging a noose made of rope from a tree near a student union, university officials said Thursday. The incident is one of several recent racist events to affect college students. In February, a noose was hung around the neck of a statue of a famous civil rights figure at the University of Mississippi.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Average ROUGE-1 F1: 0.2673\n",
            "Average ROUGE-2 F1: 0.0959\n",
            "Average ROUGE-L F1: 0.2465\n",
            "\n",
            "Complete! Evaluation finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}